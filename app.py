import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin


def crawl_and_save_blog_post(blog_id: str, post_num: str) -> str:
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ IDì™€ ê²Œì‹œë¬¼ ë²ˆí˜¸ë¥¼ ë°›ì•„ HTMLê³¼ CSSë¥¼ ê²°í•©í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        blog_id (str): í¬ë¡¤ë§í•  ë„¤ì´ë²„ ë¸”ë¡œê·¸ ID
        post_num (str): í¬ë¡¤ë§í•  ê²Œì‹œë¬¼ ë²ˆí˜¸

    Returns:
        str: ì €ì¥ëœ íŒŒì¼ì˜ ê²½ë¡œ ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€
    """
    # 1. URL ìƒì„± ë° HTML ê°€ì ¸ì˜¤ê¸°
    # ë„¤ì´ë²„ ë¸”ë¡œê·¸ëŠ” ëª¨ë°”ì¼ ë²„ì „ í˜ì´ì§€ê°€ êµ¬ì¡°ê°€ ë” ê°„ë‹¨í•˜ê³  CSS ì²˜ë¦¬ê°€ ìš©ì´í•©ë‹ˆë‹¤.
    target_url = f"https://m.blog.naver.com/{blog_id}/{post_num}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    try:
        response = requests.get(target_url, headers=headers)
        response.raise_for_status()  # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
    except requests.exceptions.RequestException as e:
        return f"âŒ ì˜¤ë¥˜: í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•˜ì„¸ìš”. ({e})"

    # 2. BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # 3. í•„ìš”í•œ ìš”ì†Œë§Œ ì¶”ì¶œ (se-main-container ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§)
    main_container = soup.find(class_='se-main-container')
    if main_container:
        # ìƒˆë¡œìš´ HTML ë¬¸ì„œ ìƒì„±
        new_soup = BeautifulSoup('<!DOCTYPE html><html><head></head><body></body></html>', 'html.parser')
        new_soup.body.append(main_container.extract())
        soup = new_soup
    
    # 4. ë¶ˆí•„ìš”í•œ ìš”ì†Œë“¤ ì œê±°
    for unwanted in soup.find_all(class_=['blog_fe_feed', 'section_t1']):
        unwanted.decompose()
    
    # 5. ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„  ë° ìŠ¤íƒ€ì¼ ì ìš©
    # ëª¨ë“  ì´ë¯¸ì§€ì˜ srcë¥¼ ê³ í•´ìƒë„ë¡œ ë³€ê²½í•˜ê³  í•„ìš”í•œ ìŠ¤íƒ€ì¼ ì¶”ê°€
    for img in soup.find_all('img', class_='se-image-resource'):
        # ì €í•´ìƒë„ ë¸”ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê³ í•´ìƒë„ë¡œ ë³€ê²½
        if img.get('src') and 'type=w80_blur' in img['src']:
            img['src'] = img['src'].replace('type=w80_blur', 'type=w800')
        
        # data-lazy-srcê°€ ìˆìœ¼ë©´ srcë¡œ ì„¤ì •
        if img.get('data-lazy-src'):
            img['src'] = img['data-lazy-src']
            
        # ì´ë¯¸ì§€ì— ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì ìš©
        img['style'] = 'display: block !important; margin-left: auto !important; margin-right: auto !important; max-width: 100% !important; height: auto !important;'
    
    # ì´ë¯¸ì§€ ë§í¬ì—ë„ ìŠ¤íƒ€ì¼ ì ìš©
    for link in soup.find_all('a', class_='se-module-image-link'):
        link['style'] = 'display: block !important; text-align: center !important; margin-left: auto !important; margin-right: auto !important; width: fit-content !important;'

    # 6. CSS ì¶”ì¶œ ë° í†µí•©
    # ëª¨ë“  <link rel="stylesheet"> íƒœê·¸ì™€ <style> íƒœê·¸ ì°¾ê¸°
    css_tags = soup.find_all(['link', 'style'])

    combined_css = ""
    for tag in css_tags:
        if tag.name == 'style':
            # <style> íƒœê·¸ ì•ˆì˜ CSS ì½”ë“œ ì§ì ‘ ì¶”ê°€
            combined_css += tag.get_text() + "\n"
        elif tag.name == 'link' and tag.get('rel') == ['stylesheet'] and 'href' in tag.attrs:
            # <link> íƒœê·¸ì˜ href ì†ì„±ì—ì„œ CSS íŒŒì¼ URL ê°€ì ¸ì˜¤ê¸°
            css_url = urljoin(target_url, tag['href'])
            try:
                css_response = requests.get(css_url, headers=headers)
                if css_response.status_code == 200:
                    combined_css += css_response.text + "\n"
            except requests.exceptions.RequestException:
                # CSS íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                pass

        # ì›ë³¸ <link>ì™€ <style> íƒœê·¸ëŠ” ì‚­ì œí•˜ì—¬ ì¤‘ë³µ ë°©ì§€
        tag.decompose()

    # 7. ê¸°ë³¸ ìŠ¤íƒ€ì¼ CSS ì¶”ê°€
    try:
        with open("style.css", "r", encoding="utf-8") as f:
            base_css = f.read()
            # <style> íƒœê·¸ê°€ ìˆë‹¤ë©´ ì œê±°í•˜ê³  ë‚´ìš©ë§Œ ì¶”ì¶œ
            if base_css.strip().startswith('<style>') and base_css.strip().endswith('</style>'):
                base_css = base_css.strip()[7:-8]  # <style>ê³¼ </style> ì œê±°
    except FileNotFoundError:
        base_css = ""

    # 8. í†µí•©ëœ CSSë¥¼ ìƒˆë¡œìš´ <style> íƒœê·¸ë¡œ ë§Œë“¤ì–´ <head>ì— ì¶”ê°€
    # ê¸°ë³¸ ìŠ¤íƒ€ì¼ì„ ë¨¼ì € ì¶”ê°€í•˜ê³ , ê·¸ ë‹¤ìŒì— í˜ì´ì§€ì˜ CSS ì¶”ê°€
    final_css = base_css + "\n" + combined_css if base_css else combined_css
    
    if final_css:
        new_style_tag = soup.new_tag('style')
        new_style_tag.string = final_css

        # ë¶ˆí•„ìš”í•œ ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ ì œê±° (ì„ íƒ ì‚¬í•­, ë¡œë”© ì†ë„ ê°œì„ )
        for script in soup.find_all('script'):
            script.decompose()

        soup.head.append(new_style_tag)

    # 9. ì™„ì„±ëœ HTMLì„ íŒŒì¼ë¡œ ì €ì¥
    output_filename = f"crawled_{blog_id}_{post_num}.html"
    with open(output_filename, "w", encoding="utf-8") as f:
        f.write(str(soup))

    return f"âœ… ì„±ê³µ! '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."


# --- Streamlit UI ë¶€ë¶„ ---
st.set_page_config(page_title="Naver Blog Crawler", page_icon="ğŸ“")

# Streamlit ë©”ë‰´ ë° íˆ´ë°” ìˆ¨ê¸°ê¸° (í”„ë¡œë•ì…˜ í™˜ê²½ìš©)
hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
.stDeployButton {display:none;}
footer {visibility: hidden;}
#stDecoration {display:none;}
header {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

st.title("ğŸ“ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ëŸ¬")
st.markdown("ë¸”ë¡œê·¸ IDì™€ ê²Œì‹œë¬¼ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ë©´, í•´ë‹¹ í¬ìŠ¤íŠ¸ì˜ HTMLê³¼ CSSë¥¼ í•©ì³ ë‹¨ì¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

st.info(
    "ğŸ’¡ **ì°¸ê³  URL**: `https://blog.naver.com/monkey_dream/223816008103`\n - **ë¸”ë¡œê·¸ ID**: `monkey_dream`\n - **ê²Œì‹œë¬¼ ë²ˆí˜¸**: `223816008103`",
    icon="â„¹ï¸")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'extraction_completed' not in st.session_state:
    st.session_state.extraction_completed = False
if 'extraction_data' not in st.session_state:
    st.session_state.extraction_data = {}
if 'download_completed' not in st.session_state:
    st.session_state.download_completed = False

# ì‚¬ìš©ì ì…ë ¥ - ì„¸ì…˜ ìƒíƒœì—ì„œ ê¸°ë³¸ê°’ ê°€ì ¸ì˜¤ê¸°
blog_id_input = st.text_input(
    "ë¸”ë¡œê·¸ ID (Blog ID)", 
    value=st.session_state.extraction_data.get('blog_id', ''),
    placeholder="ì˜ˆ: monkey_dream"
)
post_num_input = st.text_input(
    "ê²Œì‹œë¬¼ ë²ˆí˜¸ (Post Number)", 
    value=st.session_state.extraction_data.get('post_num', ''),
    placeholder="ì˜ˆ: 223816008103"
)

if st.button("ğŸš€ ì¶”ì¶œ ì‹œì‘!"):
    st.markdown("---")
    if blog_id_input and post_num_input:
        with st.spinner("ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ í¬ë¡¤ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            result_message = crawl_and_save_blog_post(blog_id_input, post_num_input)

        if "ì„±ê³µ" in result_message:
            # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
            output_filename = f"crawled_{blog_id_input}_{post_num_input}.html"
            with open(output_filename, "r", encoding="utf-8") as f:
                html_content = f.read()
            
            st.session_state.extraction_completed = True
            st.session_state.extraction_data = {
                'blog_id': blog_id_input,
                'post_num': post_num_input,
                'html_content': html_content,
                'output_filename': output_filename,
                'original_url': f"https://blog.naver.com/{blog_id_input}/{post_num_input}",
                'result_message': result_message
            }
            st.session_state.download_completed = False
            
            st.success(result_message)
        else:
            st.error(result_message)
            st.session_state.extraction_completed = False
    else:
        st.warning("ë¸”ë¡œê·¸ IDì™€ ê²Œì‹œë¬¼ ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.session_state.extraction_completed = False

# ì¶”ì¶œ ì™„ë£Œëœ ê²½ìš° ê²°ê³¼ í‘œì‹œ
if st.session_state.extraction_completed:
    st.markdown("---")
    
    data = st.session_state.extraction_data
    
    # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ
    if st.session_state.download_completed:
        st.success("âœ… ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì›ë³¸ ë¸”ë¡œê·¸ ë§í¬ í‘œì‹œ
    st.info(f"ğŸ”— **ì›ë³¸ ë¸”ë¡œê·¸ ë§í¬**: [{data['original_url']}]({data['original_url']})")
    
    # HTML ë¯¸ë¦¬ë³´ê¸° ë° ë³µì‚¬ ê¸°ëŠ¥
    col1, col2 = st.columns(2)
    
    with col1:
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í´ë¦­ ì‹œ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        if st.download_button(
            label=f"ğŸ“„ {data['output_filename']} ë‹¤ìš´ë¡œë“œ",
            data=data['html_content'],
            file_name=data['output_filename'],
            mime='text/html',
            key="download_btn"
        ):
            st.session_state.download_completed = True
            st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ
    
    with col2:
        # JavaScript ê¸°ë°˜ í´ë¦½ë³´ë“œ ë³µì‚¬ ê¸°ëŠ¥
        copy_button_html = f"""
        <style>
        .copy-button {{
            background-color: #ff4b4b;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 0.5rem;
            cursor: pointer;
            font-size: 14px;
            margin: 10px 0;
        }}
        .copy-button:hover {{
            background-color: #ff6b6b;
        }}
        #html-content {{
            position: absolute;
            left: -9999px;
        }}
        </style>
        <textarea id="html-content" readonly>{data['html_content']}</textarea>
        <button class="copy-button" onclick="copyToClipboard()">ğŸ“‹ HTML í´ë¦½ë³´ë“œì— ë³µì‚¬</button>
        <div id="copy-message" style="color: green; font-size: 12px; margin-top: 5px;"></div>
        
        <script>
        function copyToClipboard() {{
            const textArea = document.getElementById('html-content');
            textArea.select();
            textArea.setSelectionRange(0, 99999);
            
            try {{
                document.execCommand('copy');
                document.getElementById('copy-message').innerHTML = 'âœ… HTMLì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!';
                setTimeout(() => {{
                    document.getElementById('copy-message').innerHTML = '';
                }}, 3000);
            }} catch (err) {{
                navigator.clipboard.writeText(textArea.value).then(() => {{
                    document.getElementById('copy-message').innerHTML = 'âœ… HTMLì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!';
                    setTimeout(() => {{
                        document.getElementById('copy-message').innerHTML = '';
                    }}, 3000);
                }}).catch(() => {{
                    document.getElementById('copy-message').innerHTML = 'âŒ ë³µì‚¬ ì‹¤íŒ¨. ìˆ˜ë™ìœ¼ë¡œ ë³µì‚¬í•´ì£¼ì„¸ìš”.';
                }});
            }}
        }}
        </script>
        """
        st.components.v1.html(copy_button_html, height=100)
    
    # HTML ì‹¤ì œ ë Œë”ë§ ë¯¸ë¦¬ë³´ê¸°
    if st.checkbox("ğŸ” HTML ë¯¸ë¦¬ë³´ê¸°", key="html_preview_checkbox"):
        st.subheader("ğŸ“„ ì¶”ì¶œëœ ë¸”ë¡œê·¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°")
        
        # HTML ë‚´ìš©ì—ì„œ body ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ í‘œì‹œ (í°ìƒ‰ ë°°ê²½ ì ìš©)
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(data['html_content'], 'html.parser')
            body_content = soup.body
            if body_content:
                # body ë‚´ìš©ì„ í°ìƒ‰ ë°°ê²½ divë¡œ ê°ì‹¸ê¸°
                preview_html = f"""
                <div style="background-color: white; padding: 20px; min-height: 100%; margin: 0;">
                    {str(body_content)}
                </div>
                """
                st.components.v1.html(preview_html, height=600, scrolling=True)
            else:
                # bodyê°€ ì—†ìœ¼ë©´ ì „ì²´ HTMLì„ í°ìƒ‰ ë°°ê²½ divë¡œ ê°ì‹¸ê¸°
                preview_html = f"""
                <div style="background-color: white; padding: 20px; min-height: 100%; margin: 0;">
                    {data['html_content']}
                </div>
                """
                st.components.v1.html(preview_html, height=600, scrolling=True)
        except:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì „ì²´ HTMLì„ í°ìƒ‰ ë°°ê²½ divë¡œ ê°ì‹¸ê¸°
            preview_html = f"""
            <div style="background-color: white; padding: 20px; min-height: 100%; margin: 0;">
                {data['html_content']}
            </div>
            """
            st.components.v1.html(preview_html, height=600, scrolling=True)